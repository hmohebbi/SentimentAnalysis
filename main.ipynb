{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 2,
    "file_extension": ".py",
    "mimetype": "text/x-python",
    "name": "python",
    "npconvert_exporter": "python",
    "pygments_lexer": "ipython3",
    "version": 3,
    "colab": {
      "name": "main.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Oq8PzYHAN8O",
        "colab_type": "text"
      },
      "source": [
        "Hosein Mohebbi\n",
        "hosein.mohebbi75@gmail.com"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qx557r76Ux5H",
        "colab_type": "text"
      },
      "source": [
        "# Downloading and Installing "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J54WUn8ZU4Lj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXYoDQj4VXeQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tar -zxvf aclImdb_v1.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhXuZg1jAomg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip3 install bert-embedding"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfdXLKSbAqgD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip3 install mxnet-cu100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k485f8bacv2d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBeYCgcDUQUd",
        "colab_type": "text"
      },
      "source": [
        "# Required Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FTdlFDxUQUh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize \n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer \n",
        "from nltk.corpus import wordnet\n",
        "from nltk.tag import pos_tag\n",
        "import re\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "# import mxnet as mx\n",
        "# from bert_embedding import BertEmbedding\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1q3l8llsUQUr",
        "colab_type": "text"
      },
      "source": [
        "# Loading DataSet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUXxV-mGUQUt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loadDataset(data_dir):\n",
        "    \n",
        "    data = {}\n",
        "    for partition in [\"train\", \"test\"]:\n",
        "        data[partition] = []\n",
        "        for sentiment in [\"neg\", \"pos\"]:\n",
        "            lable = 1 if sentiment == \"pos\" else -1\n",
        "\n",
        "            path = os.path.join(data_dir, partition, sentiment)\n",
        "            files = os.listdir(path)\n",
        "            for f_name in files:\n",
        "                with open(os.path.join(path, f_name), \"r\") as f:\n",
        "                    review = f.read()\n",
        "                    data[partition].append([review, lable])\n",
        "\n",
        "    np.random.shuffle(data[\"train\"])\n",
        "    np.random.shuffle(data[\"test\"])\n",
        "    \n",
        "    data[\"train\"] = pd.DataFrame(data[\"train\"],\n",
        "                                 columns=['text', 'sentiment'])\n",
        "    data[\"test\"] = pd.DataFrame(data[\"test\"],\n",
        "                                columns=['text', 'sentiment'])\n",
        "\n",
        "    return data[\"train\"], data[\"test\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4qI30GJUQU0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_dir = \"aclImdb/\"\n",
        "train_data, test_data = loadDataset(data_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qF7qiXVUQU6",
        "colab_type": "text"
      },
      "source": [
        "# Cleaning Dataset\n",
        "Removing HTML tags and punctuation as well as Lowering text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjozN_Dlr6Bs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# POS Tagging\n",
        "def NormalizeWithPOS(word_list):\n",
        "  \n",
        "    lemmatizer = WordNetLemmatizer() \n",
        "    stemmer = PorterStemmer() \n",
        "    for word, tag in pos_tag(word_list):\n",
        "        if tag.startswith('J'):\n",
        "            w = lemmatizer.lemmatize(word, pos='a')\n",
        "        elif tag.startswith('V'):\n",
        "            w = lemmatizer.lemmatize(word, pos='v')\n",
        "        elif tag.startswith('N'):\n",
        "            w = lemmatizer.lemmatize(word, pos='n')\n",
        "        elif tag.startswith('R'):\n",
        "            w = lemmatizer.lemmatize(word, pos='r')\n",
        "        else:\n",
        "            w = word\n",
        "        w = stemmer.stem(word)\n",
        "        yield w"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXdzWU9bUQU8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cleanText(text):\n",
        "    \n",
        "    text = re.sub(r'<.*?>', ' ', text)\n",
        "    text = re.sub(r\"[0-9]+\", ' ', text)\n",
        "    \n",
        "    text = re.sub(r\"won\\'t\", \"will not\", text)\n",
        "    text = re.sub(r\"can\\'t\", \"can not\", text)\n",
        "    text = re.sub(r\"n\\'t\", \" not\", text)\n",
        "    \n",
        "    text = text.strip().lower()\n",
        "    \n",
        "    # Remove Stop words\n",
        "    default_stop_words = set(stopwords.words('english'))\n",
        "    default_stop_words.difference_update({'no', 'not', 'nor', 'too', 'any'})\n",
        "    stop_words = default_stop_words.union({\"'m\", \"n't\", \"'d\", \"'re\", \"'s\",\n",
        "                                           'would', 'must', \"'ve\", \"'ll\", \n",
        "                                           'may'})\n",
        "    \n",
        "    word_list = word_tokenize(text)\n",
        "    filtered_list = [w for w in word_list if not w in stop_words]\n",
        "    text = ' '.join(filtered_list)\n",
        "    \n",
        "    # Remove other contractions\n",
        "    text = re.sub(r\"\\'\", '', text)\n",
        "    \n",
        "    # Replace punctuations with space\n",
        "    filters='!\"\\'#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n'\n",
        "    translate_dict = dict((i, \" \") for i in filters)\n",
        "    translate_map = str.maketrans(translate_dict)\n",
        "    text = text.translate(translate_map)\n",
        "    \n",
        "    text = ' '.join([w for w in text.split() if len(w)>1])\n",
        "    # Replace multiple space with one space\n",
        "    text = re.sub(' +', ' ', text)\n",
        "    \n",
        "    # Lemmatization & Stemming \n",
        "    text = ' '.join(NormalizeWithPOS(word_tokenize(text)))\n",
        "  \n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDCYc1vjub2T",
        "colab_type": "code",
        "outputId": "25fc1618-9e51-4d25-e8ba-8520455abd4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "# Debugging\n",
        "txt = train_data.iloc[61]['text']\n",
        "a = cleanText(txt)\n",
        "print(txt, end=\"\\n\\n\")\n",
        "print(a)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "While this outing certainly doesn't live up to its predecessor, it does have more than its share of memorable moments. My personal favorite, just after laying waste to a city block with his \"Videodisc Cannon,\" we see a close up of Nimoy's face. As a single tear sheds from his left eye, we know at that point that Nimoy is more than just a killing machine. The viewer can't help but be pulled into his emotional turmoil and we understand that his previously flat affect was only a facade. Absolute brilliance!!! The sex scenes display a nice balance, carnal, but not pornographic. Afterwards, I felt I had a pretty good understanding of how to work the Magnavision Videodisc Player. Too bad they haven't produced them in over 25 years.\n",
            "\n",
            "outing certainli not live predecessor share memor moment person favorit lay wast citi block videodisc cannon see close nimoy face singl tear shed left eye know point nimoy kill machin viewer not help pull emot turmoil understand previous flat affect facad absolut brillianc sex scene display nice balanc carnal not pornograph afterward felt pretti good understand work magnavis videodisc player too bad not produc year\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0DdXKob-3Dh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    default_stop_words = set(stopwords.words('english'))\n",
        "    default_stop_words.difference_update({'no', 'not', 'nor', 'too', 'any'})\n",
        "    temp = set(\n",
        "                {'were',\n",
        " 'he',\n",
        " 'our'\n",
        " 'ought',\n",
        " 'may',\n",
        " 'they',\n",
        " 'where',\n",
        " \"'re\",\n",
        " 'was',\n",
        " 'must',\n",
        " 'would',\n",
        " 'why',\n",
        " 'has',\n",
        " 'we',\n",
        " 'when',\n",
        " 'should',\n",
        " 'does',\n",
        " \"n't\",\n",
        " 'is',\n",
        " \"'ve\",\n",
        " 'it',\n",
        " \"'ll\",\n",
        " 'you',\n",
        " \"'ll\",\n",
        " 'did',\n",
        " \"'ve\",\n",
        " 'would',\n",
        " 'that',\n",
        " \"'d\",\n",
        " 'they',\n",
        " \"'d\",\n",
        " 'will',\n",
        " 'there',\n",
        " 'who',\n",
        " 'she',\n",
        " \"'ll\",\n",
        " 'i',\n",
        " \"'m\",\n",
        " \"'s\",\n",
        " 'you',\n",
        " \"'re\",\n",
        " \"'ve\",\n",
        " \"'d\",\n",
        " \"'ve\",\n",
        " \"n't\"})\n",
        "    \n",
        "    temp.difference_update(default_stop_words)\n",
        "    print(temp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "taLGylY9UQVC",
        "colab_type": "text"
      },
      "source": [
        "# Vectorization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JHLEqM7UQVG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Bag Of Words (BOW)\n",
        "vectorizer = CountVectorizer(preprocessor=cleanText, max_features=20000)\n",
        "\n",
        "training_features = vectorizer.fit_transform(train_data[\"text\"])    \n",
        "test_features = vectorizer.transform(test_data[\"text\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmxWcw2drO-o",
        "colab_type": "code",
        "outputId": "42101b4f-1b80-4597-9117-b4aa3890d2aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "training_features.shape"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 50324)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OspmKZvUQVL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# BERT Embedding"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRVl3eAoWnWX",
        "colab_type": "text"
      },
      "source": [
        "# Classifiers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvVoVtNQXTME",
        "colab_type": "text"
      },
      "source": [
        "# Model & Training & Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CL41dcagW1ZX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# SVM \n",
        "param_grid = [{'kernel': ['rbf'], 'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
        "                     'C': [1, 10, 100, 1000]},\n",
        "                    {'kernel': ['linear'], 'C': [0.1, 1, 10, 100]}]\n",
        "grid = GridSearchCV(SVC(), param_grid, refit = True, cv=5)\n",
        "\n",
        "# Training \n",
        "grid.fit(training_features, train_data[\"sentiment\"])\n",
        "\n",
        "# Evaluation\n",
        "y_pred = grid.predict(test_features)\n",
        "\n",
        "print(grid.best_params_) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zISF4GZUXuIe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Naive Bayes classifier\n",
        "# model = GaussianNB()\n",
        "# model.fit(training_features.toarray(), train_data[\"sentiment\"])\n",
        "# y_pred = model.predict(test_features.toarray())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZ7WCrVEX59x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Decision tree classifier\n",
        "# model = DecisionTreeClassifier()\n",
        "# model.fit(training_features, train_data[\"sentiment\"])\n",
        "# y_pred = model.predict(test_features)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhQkqcY_YpWb",
        "colab_type": "text"
      },
      "source": [
        "# Result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nB0lRUTUQVl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc = accuracy_score(test_data[\"sentiment\"], y_pred)\n",
        "# Result\n",
        "print(\"Accuracy: {:.2f}\".format(acc*100))\n",
        "cm = confusion_matrix(test_data[\"sentiment\"],y_pred)\n",
        "print(cm)\n",
        "print(classification_report(test_data[\"sentiment\"],y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OwMgDB5gec-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}