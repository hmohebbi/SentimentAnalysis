{"cells":[{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":"# Required Packages"},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":"import os\nimport numpy as np\nimport pandas as pd\nimport nltk\nnltk.download('punkt')\nimport re\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier\n"},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":"# Loading DataSet"},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":"def loadDataset(data_dir):\n    \n    data = {}\n    for partition in [\"train\", \"test\"]:\n        data[partition] = []\n        for sentiment in [\"neg\", \"pos\"]:\n            lable = 1 if sentiment == \"pos\" else -1\n\n            path = os.path.join(data_dir, partition, sentiment)\n            files = os.listdir(path)\n            for f_name in files:\n                with open(os.path.join(path, f_name), \"r\") as f:\n                    review = f.read()\n                    data[partition].append([review, lable])\n\n    np.random.shuffle(data[\"train\"])\n    np.random.shuffle(data[\"test\"])\n    \n    data[\"train\"] = pd.DataFrame(data[\"train\"],\n                                 columns=['text', 'sentiment'])\n    data[\"test\"] = pd.DataFrame(data[\"test\"],\n                                columns=['text', 'sentiment'])\n\n    return data[\"train\"], data[\"test\"]"},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":"data_dir = \"../DataSet/aclImdb/\"\ntrain_data, test_data = loadDataset(data_dir)"},{"cell_type":"markdown","execution_count":16,"metadata":{},"outputs":[],"source":"# Cleaning Dataset\nRemoving HTML tags and punctuation as well as Lowering text."},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":"def cleanText(text):\n    \n    text = re.sub(r'<.*?>', '', text)\n    text = re.sub(r\"\\\\\", \"\", text)    \n    text = re.sub(r\"\\'\", \"\", text)    \n    text = re.sub(r\"\\\"\", \"\", text) \n    text = text.strip().lower()\n    # replace punctuation characters with spaces\n    filters='!\"\\'#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n'\n    translate_dict = dict((i, \" \") for i in filters)\n    translate_map = str.maketrans(translate_dict)\n    text = text.translate(translate_map)\n\n    return text"},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":"# Vectorization"},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":"# Bag Of Words (BOW)"},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":"# BOW\nvectorizer = CountVectorizer(stop_words=\"english\",\n                             preprocessor=cleanText)\n\ntraining_features = vectorizer.fit_transform(train_data[\"text\"])    \ntest_features = vectorizer.transform(test_data[\"text\"])"},{"cell_type":"markdown","execution_count":0,"metadata":{},"outputs":[],"source":"# BERT Embedding"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":""},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":"# Support vector machine (SVM) classifier"},{"cell_type":"markdown","execution_count":25,"metadata":{},"outputs":[],"source":"# SVM - Linear Kernel"},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":"# Training \nmodel = SVC(kernel = 'linear', C = 1)\nmodel.fit(training_features, train_data[\"sentiment\"])\ny_pred = model.predict(test_features)"},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":"# Evaluation\nacc = accuracy_score(test_data[\"sentiment\"], y_pred)"},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Accuracy: 83.31\n[[10560  1940]\n [ 2233 10267]]\n              precision    recall  f1-score   support\n\n          -1       0.83      0.84      0.84     12500\n           1       0.84      0.82      0.83     12500\n\n    accuracy                           0.83     25000\n   macro avg       0.83      0.83      0.83     25000\nweighted avg       0.83      0.83      0.83     25000\n\n"}],"source":"# Result\nprint(\"Accuracy: {:.2f}\".format(acc*100))\ncm = confusion_matrix(test_data[\"sentiment\"],y_pred)\nprint(cm)\nprint(classification_report(test_data[\"sentiment\"],y_pred))"},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":"# SVM - Gaussian Kernel"},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":"# Training\nmodel = SVC(kernel='rbf', gamma='scale')\nmodel.fit(training_features, train_data[\"sentiment\"])\ny_pred = model.predict(test_features)"},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":"# Evaluation\nacc = accuracy_score(test_data[\"sentiment\"], y_pred)"},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Accuracy: 86.69\n[[10600  1900]\n [ 1427 11073]]\n              precision    recall  f1-score   support\n\n          -1       0.88      0.85      0.86     12500\n           1       0.85      0.89      0.87     12500\n\n    accuracy                           0.87     25000\n   macro avg       0.87      0.87      0.87     25000\nweighted avg       0.87      0.87      0.87     25000\n\n"}],"source":"# Result\nprint(\"Accuracy: {:.2f}\".format(acc*100))\ncm = confusion_matrix(test_data[\"sentiment\"],y_pred)\nprint(cm)\nprint(classification_report(test_data[\"sentiment\"],y_pred))"},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":"# SVM - Sigmoid Kernel"},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":"/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n  \"avoid this warning.\", FutureWarning)\n"}],"source":"# Training\nmodel = SVC(kernel='sigmoid')\nmodel.fit(training_features, train_data[\"sentiment\"])\ny_pred = model.predict(test_features)"},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":"# Evaluation\nacc = accuracy_score(test_data[\"sentiment\"], y_pred)"},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Accuracy: 56.88\n[[ 2123 10377]\n [  402 12098]]\n              precision    recall  f1-score   support\n\n          -1       0.84      0.17      0.28     12500\n           1       0.54      0.97      0.69     12500\n\n    accuracy                           0.57     25000\n   macro avg       0.69      0.57      0.49     25000\nweighted avg       0.69      0.57      0.49     25000\n\n"}],"source":"# Result\nprint(\"Accuracy: {:.2f}\".format(acc*100))\ncm = confusion_matrix(test_data[\"sentiment\"],y_pred)\nprint(cm)\nprint(classification_report(test_data[\"sentiment\"],y_pred))"},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":"# Naive Bayes classifier"},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":"# Training\nmodel = GaussianNB()\nmodel.fit(training_features, train_data[\"sentiment\"]) "},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":"# Evaluation\ny_pred = model.predict(test_features) \nacc = accuracy_score(test_data[\"sentiment\"], y_pred) "},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":"# Result\nprint(\"Accuracy: {:.2f}\".format(acc*100))\ncm = confusion_matrix(test_data[\"sentiment\"],y_pred)\nprint(cm)\nprint(classification_report(test_data[\"sentiment\"],y_pred))"},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":"# Decision tree classifier"},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":"# Training\nmodel = DecisionTreeClassifier()\nmodel.fit(training_features, train_data[\"sentiment\"])"},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":"# Evaluation\ny_pred = model.predict(test_features)\nacc = accuracy_score(test_data[\"sentiment\"], y_pred)"},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":"# Result\nprint(\"Accuracy: {:.2f}\".format(acc*100))\ncm = confusion_matrix(test_data[\"sentiment\"],y_pred)\nprint(cm)\nprint(classification_report(test_data[\"sentiment\"],y_pred))"}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}